{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdtqyejvgRs3"
   },
   "source": [
    "# FIBONACCI TURING MACHINE TUTORIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Author: Elisabeth Llanos Pla and Júlia Barberà Rodríguez*, 16th February of 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents a design and implementation to determine if a number belongs to the Fibonacci sequence using a Turing Machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Table of contents:__\n",
    "\n",
    "0. [Introduction](#1)\n",
    "\n",
    "\n",
    "\n",
    "1. [The Turing Machines for this problem](#1)\n",
    "\n",
    "    1.1. [ Binary Turing Machine computing the numbers of the sequence](#1)\n",
    "    \n",
    "    1.2. [Unary Turing Machine computing the numbers of the sequence](#1)\n",
    "    \n",
    "    1.3. [Fibonacci formula Turing Machine](#1)\n",
    "     \n",
    "     \n",
    "    \n",
    "2. [Implementation](#1)\n",
    "\n",
    "    2.1. [The text file](#1)\n",
    "    \n",
    "    2.2. [The code](#1)\n",
    "    \n",
    "    2.3. [Examples](#1)\n",
    "    \n",
    "    \n",
    "\n",
    "3. [Complexity analysis](#1)\n",
    "\n",
    "    3.1. [ Binary Turing Machine computing the numbers of the sequence](#1)\n",
    "    \n",
    "    3.2. [Unary Turing Machine computing the numbers of the sequence](#1)\n",
    "    \n",
    "    3.3. [Fibonacci formula Turing Machine](#1)\n",
    "    \n",
    "    \n",
    "    \n",
    "4. [Comparison and conclusions](#1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFPlRV5FGXow"
   },
   "source": [
    "## 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qY9ayZfiCYni"
   },
   "source": [
    "A Turing Machine is a mathematical model of computation whose aim is to solve some problem by manipulating symbols on a tape according to certain rules and transitions which have been set for that specific problem. \n",
    "\n",
    "In this notebook we expose the design, implementation, and complexity analysis of a Turing Machine that determines if a given number belongs to the Fibonacci sequence. The well-known Fibonacci sequence, commonly denoted $F_n$, is a sequence of numbers in which each number is the sum of the two previous ones. The sequence generally starts with \"1\" and \"1\", and follows with the sum of these two numbers: 1 + 1 = 2. The first four numbers of the sequence are then $0,1,1,2$, and the next one is computed by adding \"1\" and “2\". We can easily find a recurrence formula:\n",
    "\t\n",
    "  $$F_n = F_{n-1} + F_{n-2}$$\n",
    "\n",
    "Which is valid for $n>1$. As the numbers get larger, the quotient between each successive pair of Fibonacci numbers approximates to 1.618. This proportion is known by “golden ratio”, or $\\phi$. By operating the recurrent formula successively, we obtain the infinite Fibonacci sequence:\n",
    "\n",
    "\n",
    "$$F_n = 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144 ... $$\n",
    "\n",
    "Some mathematicians exclude the “0” from the sequence, starting it with the number “1”. For practical reasons, we have also excluded the “0”, whose absence does not affect the overall analysis of our Turing Machine.\n",
    "\n",
    "We can also determine if a given number $n$ belongs to the Fibonacci sequence by checking if one of the following expressions gives as a result a perfect square:\n",
    "\n",
    "$$5n^2+4 \\hspace{0.5cm},\\hspace{0.5cm} 5n^2-4$$\n",
    "\n",
    "\n",
    "Fibonacci sequence astonishing presence in nature, points out its important role in the behavior and formation of many features in the Universe. Emergent patterns and ratios can be observed from the microscale to the macroscale; for example, the numbers of petals in a flower, the splitting of tree branches, animal fight patterns, the spiral galaxies shape … they are all Fibonacci numbers or follow the Fibonacci pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEpk46mFHD4b"
   },
   "source": [
    "## 1. The Turing Machines for this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyvuFnvAcoys"
   },
   "source": [
    "A Turing Machine consists of different elements: \n",
    "\n",
    "\n",
    "*   A tape divided with different cells, each cell containing a different symbol of the alphabet. \n",
    "*   A head positioned over one of these cells that moves left or right depending on the transition associated to the cell that is reading. \n",
    "* The states represented by $q_i$. They contain the initial state and the final state. \n",
    "* A table filled with the different instructions (transitions) that the head needs to perform depending on the cell that it is reading and the actual state. This table is usually filled such that the columns are: {$q_0$, $s_0$, $s_f$, $r/l$, $q_f$}, where $q_0$ stands for the current state, $s_0$ is the symbol that the head is reading, $s_f$ is the symbol that will replace $s_0$, $r/l$ is the movement of the head (right or left) and $q_f$ the final state of the transition.\n",
    "\n",
    "The process starts at some initial state $q_0$ and after doing the corresponding transitions, the Turing Machine will halt at a given state and will return the updated tape as the output. \n",
    "\n",
    "We have built three different Turing Machines that determine in three different ways if a given number belongs to the Fibonacci sequence (see sections 1.1, 1.2 and 1.3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdgT0SH3fceu"
   },
   "source": [
    "### 1.1. Binary Turing Machine computing the numbers of the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4Of64wDf2sc"
   },
   "source": [
    "In this section we describe the functioning of a Turing Machine that determines if a number $k$ expressed in binary format (for example k ='10010') belongs to the sequence, by generating the numbers of the Fibbonaci sequence (FS) and comparing them to the given number. \n",
    "\n",
    "$\\textbf{Tapes}$: We have used two differents tapes.\n",
    "\n",
    "* Input tape: consists of a N bit string containing the number $k$ expressed in binary format, such that we want to check if $k \\in FS$.\n",
    "\n",
    "* Fibonacci tape: it initially contains the string '1p1', which are the two first numbers of the FS (expressed in binary) separated by a '$p$'. In this tape we will generate the subsequent numbers of the FS, so it will have the format '$F_{n-1}pF_{n}$' or $F_{n}pF_{n-1}$. As we keep forward, the TM will replace $F_{n-1}$ by $F_{n+1}$; therefore, we will always have two consecutive numbers of the FS in this tape.\n",
    "\n",
    "$\\textbf{Alphabet}: \\{0,1,p,b,y,n\\}$. \n",
    "\n",
    "The $0$ and $1$ are used to represent the numbers in binary format, the $p$ is used to separate two consecutive numbers in the 'Fibonacci tape', the $b$ symbol is a 'blank space', also denoted by '_', and $y$ and $n$ are used to ease the operations that the TM will perform.\n",
    "\n",
    "The Turing Machine operates the following way:\n",
    "1. Compare the number of bits of the input number $k$ and one of the numbers in the Fibonacci tape $F_n$. If they do not have the same number of bits, add zeros in front of the binary number of less bits, in order to equalize the length of both numbers $k$ and $F_n$.\n",
    "\n",
    "2. Once $k$ and $F_n$ have the same length, determine which of them is greater.\n",
    "\n",
    "* If $k$ = $F_n$, $k$ belongs to the FS, and the Turing Machine halts.\n",
    "\n",
    "* If $k< F_n$, $k$ does not belong to the FS, and the Turing Machine halts.\n",
    "\n",
    "* If $k>F_n$, we can not conclude anything and we follow the procedure (go to step 3).\n",
    "\n",
    "3. Add a zero in front of each binary number of the Fibonacci tape. This will be useful to perform step 4 in a easier way.\n",
    "\n",
    "4. Sum the two numbers appearing in the Fibonacci tape ($'F_npF_{n-1}1'$ or $'F_{n-1}pF_{n}1'$) and replace $F_{n-1}$ by the result of the sum, which is indeed the next number of the Fibonacci sequence $F_{n+1}$.\n",
    "\n",
    "\n",
    "This procedure will be repeated until the Turing Machine halts. We can notice that, at each loop, the result of the sum will alternatively appear in a different side of '$p$' in the Fibonacci tape, so that we always have two consecutive Fibonacci numbers. At each loop $L_i$, the Fibonacci tape will be:\n",
    "\n",
    "$$L_1: 1p1 \\longrightarrow L_2: 01p10 ⟶ L_3: 11p10 ⟶ L_4: 011p100 ...$$\n",
    "\n",
    "Therefore, in step 1, we will compare the binary number $k$ with a Fibonacci number placed alternatively on each side of $'p'$.\n",
    "\n",
    "Our Turing Machine will be divided in 4 main subroutines, which will be linked at the end. Next, we give a brief explanation of the functioning of each one of these subroutines.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLUem-ntxKKa"
   },
   "source": [
    "### *Subroutine for comparing the number of bits of $k$ and $F_n$*\n",
    "\n",
    "In order to determine if a binary number is greater than another, both numbers must have the same length. Therefore, this subroutine is used to compare the length of both numbers, and react accordingly. \n",
    "\n",
    "To do so, we place the head of both tapes (input tape and Fibonacci tape) on the last digit of the numbers that we are comparing. If we read a 0 or a 1 in both tapes, we move to the left until we read a digit in one tape, and a blank (or a '$p$') in the other. Two situations can happen:\n",
    "\n",
    "* We read a 0 or 1 in the Fibonacci tape and we read a blank in the input tape. In this case, we can simply add zeros in front of the binary input number $k$ until both heads read a blank (or a '$p$'). \n",
    "\n",
    "$\\hspace{1cm}$ An example would be:\n",
    "$$Input\\_tape: 10$$\n",
    "$$Fibonacci\\_tape: 1101p1000$$\n",
    "$\\hspace{1cm}$ After the subroutine, these tapes would have changed as:\n",
    "$$Input\\_tape: 0010$$\n",
    "$$Fibonacci\\_tape: 1101p1000$$\n",
    "\n",
    "* We read a 0 or 1 in the input tape and we read a blank or a '$p$' in the Fibonacci tape. In this case, we will have to add as many zeros as needed in front of the binary numbers in the Fibonacci tape (in both of them, in order to ensure that all the numbers appearing in our problem have the same length). To do so, we will use another subroutine: $\\textit{Subroutine for adding a zero in front of the Fibonacci numbers}$ as many times as zeros needed to equalize the lengths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBMr5csB2ZGy"
   },
   "source": [
    "### *Subroutine for comparing two binary numbers of the same length*\n",
    "\n",
    "Once the input number $k$ and the Fibonacci number $F_n$ that we are focusing on have the same number of bits, we can proceed to determine which one is greater. To do so, we place each head on the first digit of each number, and we check if the digits match. If we read a 0 or a 1 in both tapes, we keep moving to the right until we find a missmatch. If we read a 0 in one tape and a 1 in another tape, the number from which we read the 1 will be the greater.\n",
    "Three situations can happen: \n",
    "\n",
    "* If we read a 0 from the input tape and a 1 from the Fibonacci tape: $k< F_n$, implying that $k$ does not belong to FS, and the Turing Machine halts. \n",
    "\n",
    "$\\hspace{1cm}$ An example would be:\n",
    "$$Fibonacci\\_tape: 010p11\\textbf{0}$$\n",
    "$$Input\\_tape:11\\textbf{1}$$\n",
    "\n",
    "* If we read a 1 from the input tape and a 0 from the Fibonacci tape: $k> F_n$, so we can not know yet if $k$ belongs to FS. We continue with the procedure previously explained.\n",
    "\n",
    "$\\hspace{1cm}$ An example would be:\n",
    "$$Fibonacci\\_tape: 010p1\\textbf{1}0$$\n",
    "$$Input\\_tape:1\\textbf{0}1$$\n",
    "\n",
    "* Finally, if all the digits of both numbers match, $k = F_n$, meaning that $k \\in FS$. In this case the Turing Machine reads a blank (or a '$p$') in both tapes, and it halts.\n",
    "\n",
    "$\\hspace{1cm}$ An example would be:\n",
    "$$Fibonacci\\_tape: 010\\textbf{p}110$$\n",
    "$$Input\\_tape:010\\textbf{_}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtZEiBOQ7Fwx"
   },
   "source": [
    "### *Subroutine for adding a zero in front of the Fibonacci numbers*\n",
    "\n",
    "The objective of this subroutine is to place a 0 in front of each one of the Fibonacci numbers appering in the Fibonacci tape. This step needs to be done to enable the subsequent sum of the two numbers in an easy way. \n",
    "\n",
    "This subroutine writes a zero in front of the first number (on the left of '$p$'), and moves the head to the right until it reaches the number on the right. Next, it shifts all the digits of this number one position to the right, leaving a blank space between them and '$p$', which is then filled with a '0'.\n",
    "\n",
    "An example would be:\n",
    "$$Fibonacci\\_tape: \\textbf{_}1000p1101 ⟶ \\textbf{0}1000p1101 ⟶ ... ⟶ 01000p\\textbf{_}1101 ⟶ 01000p\\textbf{0}1101$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2tiC8bK_a7b"
   },
   "source": [
    "### *Subroutine for the addition of two consecutive numbers of the Fibonacci sequence*\n",
    "\n",
    "The last step of the loop is to sum up the two Fibonacci numbers that appear in the Fibonacci tape. The idea is to always have two consecutive numbers: either '$F_npF_{n-1}$' or '$F_{n-1}pF_n$'. Therefore, we want the sum of $F_n+F_{n-1} = F_{n+1}$ to replace $F_{n-1}$. We can see that, to achieve it, at each loop the result of the sum will be placed alternatively on a different side of $p$. For this reason, we need two different subroutines, which perform essentialy the same task, with the difference that they sum 'towards the right' or 'towards the left'. Here we will explain the one that perfoms the addition on the right side, i.e, the situation in which we have $F_npF_{n-1}$. \n",
    "\n",
    "We will give an example for the addition of two consecutive numbers of the sequence: 21 and 13 in binary, so we initially have:\n",
    "\n",
    "$$Fibonacci\\_tape: 010101p001101  $$\n",
    "\n",
    "For this subroutine we leave the input tape aside and we work only on the Fibonacci tape. Moreover, we use the '$y$' and '$n$' symbols to cross out '1' and '0' respectively.\n",
    "\n",
    "The procedure that the TM performs for adding two binary numbers is the following:\n",
    "\n",
    "1. We start by placing the head on the last digit of the number on the left of $p$. \n",
    "\n",
    "2. If we read a '0', we replace it by the symbol '$n$', and if we read a '1', we replace it by the symbol '$y$'.\n",
    "\n",
    "$$Fibonacci\\_tape: 01010\\textbf{1}p001101 ⟶ 01010\\textbf{y}p001101   $$\n",
    "\n",
    "3. We move to the right until the head is placed on the last digit (1 or 0) of the number on the right of $p$. \n",
    "\n",
    "$$ Fibonacci\\_tape: 01010\\textbf{y}p001101 \\longrightarrow ... ⟶  01010yp00110\\textbf{1}    $$\n",
    "\n",
    "$\\hspace{1cm}$ Two different cases need to be distinguished here:\n",
    "\n",
    "$\\hspace{1.5cm} \\bullet$ If in step 1 we had read a '0', and now we are also reading a '0', we replace it with a '$n$'. If we are reading a '1', we replace it by '$y$'. \\\\\n",
    "\n",
    "$\\hspace{1.5cm} \\bullet$ If in step 1 we had read a '1', if we now are reading a '0', replace it by a '$y$'. If we are reading a '1', we need to: \n",
    "\n",
    "$\\hspace{2cm}$ 3.1. Replace it by a '$n$' and move one position to the left. \n",
    "\n",
    "$\\hspace{2cm}$ 3.2. If we are reading a '0', replace it by a '1', and go to step 4.\n",
    "\n",
    "$\\hspace{2cm}$ 3.3. If we are reading a '1', replace it by a '0'. Move one position to the left, and go back to step 3.2. \n",
    "\n",
    "$\\hspace{2.8cm}$ Here we can appreciate the importance of having added a zero between $p$ and the binary number.\n",
    "\n",
    "$$ Fibonacci\\_tape: 01010yp00110\\textbf{1}  ⟶  01010yp00110\\textbf{n} ⟶  01010yp0011\\textbf{0}n ⟶  01010yp0011\\textbf{1}n  $$\n",
    "\n",
    "4. Move the head to the left until it is placed on the following digit of the first number, and repeat steps 3 and 4, until there are no more '0' or '1' to cross out. Following this procedure on the example, we would obtain:\n",
    "\n",
    "$$ Fibonacci\\_tape: 01010yp0011\\textbf{1}n ⟶ ... ⟶  0101\\textbf{0}yp00111n  ⟶  0101\\textbf{n}yp00111n ⟶ ... ⟶ 0101nyp0011\\textbf{1}n ⟶ \\\\\n",
    "\\hspace{3.6cm} 0101nyp0011\\textbf{y}n ⟶ ... \\longrightarrow 010\\textbf{1}nyp0011yn ⟶ 010\\textbf{y}nyp0011yn ⟶ ... ⟶ 010ynyp001\\textbf{1}yn ⟶\\\\\n",
    "\\hspace{3.6cm} 010ynyp001\\textbf{n}yn ⟶ ... ⟶ 010ynyp00\\textbf{1}nyn ⟶ 010ynyp00\\textbf{0}nyn ⟶ ... ⟶ 010ynyp0\\textbf{0}0nyn ⟶ \\\\\n",
    "\\hspace{3.6cm} 010ynyp0\\textbf{1}0nyn ⟶ ......... ⟶ nynynypynnnyn  $$\n",
    "\n",
    "5. Once we have crossed out all the digits, we replace the '$n$' by '0' and the '$y$' by '1':\n",
    "\n",
    "$$Fibonacci\\_tape: nynynypynnnyn ⟶ 010101p100010  $$\n",
    "\n",
    "We see that the resulting tape contains, on the left, the original number (21), and on the right, the result of the addition (21+13 = 34).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28hIuX5w117G"
   },
   "source": [
    "In the next figure we can see the resulting Turing Machine with all the subroutines connected. Each subroutine is indicated by a color:\n",
    "\n",
    "$\\bullet $ BLUE: Subroutine for comparing the number of bits of $k$ and $F_n$ \n",
    "\n",
    "$\\bullet $ ORANGE: Subroutine for comparing two binary numbers of the same length\n",
    "\n",
    "$\\bullet $ PURPLE: Subroutine for adding a zero in front of the Fibonacci numbers\n",
    "\n",
    "$\\bullet $ GREEN: Subroutine for the addition of two consecutive numbers of the Fibonacci sequence (addition on the right side of $p$) \n",
    "\n",
    "$\\bullet $ RED: Subroutine for the addition of two consecutive numbers of the Fibonacci sequence (addition on the left side of $p$)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAtqj0EB37Xi"
   },
   "source": [
    "![q0.png](q0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVYY8s7jc_hF"
   },
   "source": [
    "### 1.2. Unary Turing Machine computing the numbers of the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functioning of this Turing Machine is essentially the same as the one described in 1.1. The main difference is that the numbers here are expressed in unary format (i.e. $3$ in unary is $111$). \n",
    "\n",
    "The Machine can be devided in three subroutines. \n",
    "\n",
    "$\\bullet $ RED: Subroutine for comparing $k$ and $F_n$, by comparing the number of ones of each number.\n",
    "\n",
    "$\\bullet $ BLUE: Subroutine for adding two numbers in the Fibonacci tape. The result of this sum is placed on the right of $p$ which is the symbol that separates two consecutive numbers of the Fibonacci sequence.\n",
    "\n",
    "$\\bullet $ GREEN: Subroutine for adding two numbers in the Fibonacci tape. The result of this sum is placed on the left of $p$ which is the symbol that separates two consecutive numbers of the Fibonacci sequence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Unary_TM1.png](Unary_TM1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ_dSNucJggV"
   },
   "source": [
    "### 1.3. Fibonacci formula Turing Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bndS5lq9ZgNF"
   },
   "source": [
    "In this section we describe how to find if a number belongs to the Fibonacci sequence using the following formula \n",
    "$$f(n) = 5n^2\\pm4.$$\n",
    "\n",
    "If $f(n)$ is a perfect square, that is, it can be decomposed as $f(n) =p^2$ with $p$ being an integer, then the number belongs to the Fibonacci sequence. \n",
    "Therefore, this section aims to construct a Turing Machine that given an integer in unary (i.e. '111' represents number 3), computes $f(n)$ and checks if the result is a perfect square. The alphabet for this Turing Machine is:\n",
    "\n",
    "$\\textbf{Alphabet}: \\{0,1,b,x,y,c,m,f,s\\}$. \n",
    "\n",
    "The idea for this Turing Machine is the following. \n",
    "\n",
    "1. Given a number in unary, compute the square of this integer. \n",
    "2. Multiply the result by $5$ in order to obtain the first term of the equation. \n",
    "3. Add four to that value. \n",
    "4. Check if the obtained result for $f(n)^+$ is a perfect square. If it is the case, we are done since the number belongs to the Fibonacci sequence. Otherwise, compute $f(n)^-$. \n",
    "5. Check if $f(n)^-$ is a perfect square. If it is fulfilled, the number is in the sequence. Otherwise, the number is not part of the succession. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4R0nma8iK1Z"
   },
   "source": [
    "The Turing Machine will be divided in 5 different subroutines that will be put together in the end. The Machine will use two different tapes, the first one will contain the result of $f(n) = 5n^2\\pm4$ and the other one will be used to check if the result is a perfect square. The second tape will be explained more explicitely in the following sections. Moreover, the general expression of the transitions will be \n",
    "$$ (1xr,bb*) \\hspace{0.5cm} or \\hspace{0.5cm} (bb*,1xr),$$ \n",
    "\n",
    "where the first term of the parenteses corresponds to the first tape's transitions and the second one to the transitions of the second tape. Usually, one of them will be fixed at a blank and the $*$ will mean that the head associated will not move. \n",
    "\n",
    "### *Subroutine for multiplication* \n",
    "\n",
    "This part of the program needs to compute a multiplication of two given numbers since at first sight the formula has two operations like this one: the square of $n$ and five times $n^2$ (we will see later that this part will be reused for different purposes).  \n",
    "\n",
    "The procedure that we have followed to multiply two numbers is the following. \n",
    "\n",
    "1. Given a tape \n",
    "$$Input\\_tape = \\_111c111\\_$$\n",
    "\n",
    "such that the numbers that we want to multiply are separated by a symbol $c$, the head will be positioned over the first symbol of it, in this case over the first $1.$ The left hand side and right hand side of the input tape will be filled with blanks. \n",
    "\n",
    "2. The Turing reads this symbol and if it is $1$, replaces the number by an $x$, \n",
    "\n",
    "$$Updated\\_tape = x11c111.$$ \n",
    "\n",
    "Then, the head moves to the right until a $c$ is found. If a $1$ is found it replaces it by a $y$, otherwise it moves to the right until it finds a $1$ such that, \n",
    "\n",
    "$$Updated\\_tape = x11cy11.$$\n",
    "\n",
    "3. The head now moves until it finds a blank character (\"_\") and writes a $1$ next to it (replacing the blank that is in that position) as \n",
    "\n",
    "$$Updated\\_tape = x11cy11\\_1.$$\n",
    "\n",
    "If a $1$ if found after the blank, the head moves until it finds a blank symbol to replace it by a $1$. We have the first symbol copied. \n",
    "\n",
    "4. The head moves to the left until a $y$ is found and moves one site to the right to substitute the former $1$ by a $y$,\n",
    "\n",
    "$$Updated\\_tape = x11cyy1\\_1.$$\n",
    "\n",
    "Then the step 3 is repeated and the second character is copied. We proceed repeating step 3 and 4 until we have \n",
    "\n",
    "$$Updated\\_tape = x11cyyy\\_111.$$\n",
    "\n",
    "All $y$ are replaced by the former symbol (which was \"1\") and then the head moves back to the first $x$ and crosses out the symbol at the right of it. Then, we repeat steps 3 and 4 again. Thus, in the end of this process, when all $1$ at the L.H.S. of the input tape are crossed by $x$ we will have a tape such that \n",
    "\n",
    "$$Updated\\_tape = xxxcyyy\\_111111111.$$\n",
    "\n",
    "The last step of this subroutine is to substitute all characters at the L.H.S. of the blank by blanks to obtain \n",
    "\n",
    "$$output\\_tape = \\_111111111\\_, $$\n",
    "\n",
    "which has nine $1$ which is the result of multiplying $3\\cdot 3$. \n",
    "\n",
    "The Turing Machine for multiplication is shown in red in the diagram of the Turing Machine below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGcyBpdcscG4"
   },
   "source": [
    "### *Subroutine for multiplying $5n^2$*\n",
    "\n",
    "Given an input tape of the form \n",
    "\n",
    "$$Input\\_tape = \\_111111111\\_$$\n",
    "\n",
    "obtained in the previous subroutine, this subroutine transforms the tape into\n",
    "\n",
    "$$Output\\_tape = \\_111111111m11111\\_.$$\n",
    "\n",
    "The motivation for this is that once the square of the number that we want to know if it belongs to the Fibonacci succession is computed, we need to calculate $5\\cdot n^2$. To be able to do that with the previous subroutine we need to rewrite the input tape in the shape mentioned where the first digit that we want to multiply is separated by a $m$ from the other digit. Thus, we need to add a $m$ after the input tape and after that write five $1$. \n",
    "\n",
    "This is an easy procedure since the TM only needs move the head of the first tape until the blank at the right is found and replace that blank by an $m$. Afterwards, replaces the first five blanks by ones. \n",
    "\n",
    "Finally, the resulting tape is again fed to the subroutine that multiplies two integers.\n",
    "\n",
    "Notice that we have written $m$ instead of $c$ to separate the two numbers that will be multiplied. This will be useful in the end of this second multiplication since the Turing Machine will know that we have already computed the first term of the equation ($5n^2$) and we will be able to compute then the whole equation. \n",
    "\n",
    "The green lines of the diagram are the ones that contain these procedure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlbRpVY_4EkZ"
   },
   "source": [
    "### *Subroutine for adding $\\pm 4$*\n",
    "\n",
    "It is a very trivial procedure to add four or substract four in a given input filled with ones such as \n",
    "\n",
    "$$ Input\\_tape = \\_11...1\\_.$$\n",
    "\n",
    "The first step of this subroutine is to bring the head to the last $1$ of the input tape. Once the head is located there, it writes a $1$ where the blank is placed. This is done four times to add four ones in the input tape such that in the end we have \n",
    "\n",
    "$$ Output\\_tape = \\_11...1\\textbf{1111}\\_.$$\n",
    "\n",
    "The bottom blue lines encircle the part where we add $4$ and the upper right blue lines enclose the transitions that compute the substraction. \n",
    "\n",
    "Notice that we have two different regions. This is due to the fact that firstly, $f(n) = 5n^2 + 4$ is computed. When the resulting value is computed, the subroutine that will be explained right after will check whether this number is a perfect square. If it is the case, we are done. However, if $f(n) = 5n^2 +4 \\neq p^2$ we have another possibility: $f(n) = 5n^2 -4 $ could be a perfect square. Therefore, the TM also needs to consider this option and that is the reason for having two blue boxes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfajnJYuCc87"
   },
   "source": [
    "### *Subroutine square root checking*\n",
    "\n",
    "We shall describe now the most complex part of the Turing Machine: the perfect square check. \n",
    "\n",
    "The input for this subroutine is a tape which contains the calculation of the function $f(n) = 5n^2 \\pm 4$ in unary ($Formula\\_tape$) and another tape ($Square\\_tape$) which is of the form \n",
    "\n",
    "$$ Square\\_tape = \\_1f1\\_.$$ \n",
    "\n",
    "The reason for this is the following. We want to compute if the result is a perfect square, therefore we can check it by multiplying each integer by itself until the number obtained in this multiplication is equal to the one given in the $Formula\\_tape$ or until the number that is a perfect square in $Square_tape$ is bigger than the one returned by $f(n).$ Thus, the subroutine which will embed the multiplication subroutine, will work as follows: \n",
    "\n",
    "1. The head of the $Formula\\_tape$ is positioned at the blank to the left of the first $1$ and the $Square\\_tape$ head is positioned at the first symbol of the second input tape.  \n",
    "\n",
    "If it reads a one, this input tape is fed to the multiplication TM that multiplicates two numbers that are separed by a symbol ($c,m,f,s$). Therefore, it computes one times one and returns a tape like \n",
    "\n",
    "$$ Square\\_tape\\_updated = \\_1\\_ .$$\n",
    "\n",
    "2. Now the TM proceeds to compare this result which is a perfect square, with the $Formula\\_tape$ that contains the result of $f(n)$. If they match, we are done: the number $n$ belongs to the succession. Otherwise two things can happen: the $Square\\_tape$ number is lower than the $Formula\\_tape$ value or viceversa. \n",
    "\n",
    "3. If the $Square\\_tape$ integer is smaller than the one in the $Formula\\_tape$ (which can checked by crossing out the ones at each tape), we need to keep going and rewrite the $Square\\_tape$ as\n",
    "\n",
    "$$ Square\\_tape\\_updated = \\_11f11\\_,$$\n",
    "\n",
    "which can be done by crossing out the ones on the left and adding them to the R.H.S. and also to the L.H.S, to have the same number in both sides. \n",
    "\n",
    "Once this is done, repeat steps 1 and 2 until the number represented in the $Formula\\_tape$ is equal the the one in the $Square\\_tape$. If the number calculated after many iterations by \n",
    "\n",
    "$$ Square\\_tape\\_updated = \\_11..1f11..1\\_.$$\n",
    "\n",
    "is equal to the value obtained with $f(n)$, we are done. The number $n$ is in the succession. Otherwise, go to 4. \n",
    "\n",
    "4. In case $f(n) = 5n^2 + 4$ is not a perfect square, we need to check if the other possibility is: $f(n) = 5n^2 - 4$. Therefore, we substract eight ones from the first input tape using the previous subroutine and then we start all over again by writing \n",
    "\n",
    "$$ Square\\_tape = \\_1f1\\_.$$\n",
    "\n",
    "Then, go to 1. \n",
    "\n",
    "There is the possibility that when comparing both tapes the $Formula\\_tape$ has a smaller number than the one computed by the this subroutine in the $Square\\_tape$. If we have already computed $f(n) = 5n^2 - 4$ and it is not a perfect square, then the number does not belong to the Fibonacci sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mELsqzfvVhc5"
   },
   "source": [
    "![image](https://drive.google.com/uc?=view&id=1NWoUe69aM0KBOkY9cBI6HmmagbQSxFTO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTZOgh-o4yw_"
   },
   "source": [
    "## 2. Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IP8pQvHWn3Ro"
   },
   "source": [
    "In this section we give a brief explanation of how to run our Turing Machines and we show their performance by giving some examples. \n",
    "\n",
    "Both the code and the text files can be found in the folder attached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJYQbADar0yK"
   },
   "source": [
    "### 2.1. The text file\n",
    "\n",
    "We have created 3 different text files containing the transitions for each one of the Turing Machines presented. \n",
    "\n",
    "Each text file contains 8 columns, corresponding to:\n",
    "1. State in which the machine is.\n",
    "2. Symbol that we are reading from the input tape.\n",
    "3. Symbol by which we want to replace the read symbol on the input tape.\n",
    "4. Direction to move the head on the input tape. \n",
    "5. State reached after the transition.\n",
    "6. Symbol that we are reading from the additional tape (used to compute the necessary operations).\n",
    "7. Symbol by which we want to replace the read symbol on the additional tape.\n",
    "8. Direction to move the head on the additional tape.\n",
    "\n",
    "One can see in the text files, that our machines have two halting conditions, corresponding to the states 'E' and 'H'. If the input number belongs to the Fibonacci sequence, the machine will halt by 'H', and if it does not, it will halt by 'E'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEReFZrLoe5V"
   },
   "source": [
    "### 2.2. The code\n",
    "\n",
    "We have used the class TuringMachine to initialize and go through all the steps of our Turing Machines. This class recieves an input tape, which is the one that contains the number $k$ (in unary or binary) such that we want to check if $k\\in FS$. We have used an additional tape, which is used to compute the necessary operations, so we also needed to define it.\n",
    "The class also recieves an input program, which is the txt file containing the transitions of the Turing Machine.\n",
    "\n",
    "Because of the different designs of the three Turing Machines that we presented, we need to do small changes in the code according to the specific machine that we want to work on. In the initialization function, one needs to comment/discomment some code depending on the TM, as indicated below. \n",
    "\n",
    "The class returns the number of steps needed for halting (useful for future complexity analysis), and the state in which the machine halts ('E' or 'H').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rGweiXcZcnF0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import itertools\n",
    "from statistics import mean\n",
    "import plotly.graph_objs as go\n",
    "from collections import deque\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "DpRrN8stHHY2"
   },
   "outputs": [],
   "source": [
    "class TuringMachine:\n",
    "    \n",
    "    def __init__(self, program, input_tape, N, state=0):\n",
    "        self.trf = {} \n",
    "        self.state = str(state)\n",
    "        self.tape = ''.join(['_']*N)\n",
    "        self.tape_fib = ''.join(['_']*N)\n",
    "        self.head = N // 2\n",
    "        self.head_fib = N // 2 \n",
    "\n",
    "     # COMMENT / DISCOMMENT DEPENDING ON THE TURING MACHINE THAT YOU ARE INTERESTED IN RUNNING\n",
    "     # --------------------------------------------------------------------------------------------\n",
    "\n",
    "     # Binary Turing Machine computing the numbers of the sequence \n",
    "        #self.tape = self.tape[:self.head-(len(input_tape)-1)] + input_tape + self.tape[self.head:]\n",
    "        #self.tape_fib = self.tape_fib[:self.head_fib-2] + '1p1' + self.tape_fib[self.head_fib:]\n",
    "\n",
    "     # Unary Turing Machine computing the numbers of the sequence\n",
    "        #self.tape = self.tape[:self.head] + input_tape + self.tape[self.head:]\n",
    "        #self.tape_fib = self.tape_fib[:self.head_fib] + '1p1' + self.tape_fib[self.head_fib:]\n",
    "\n",
    "     # Fibonacci formula Turing Machine\n",
    "        input_tape = input_tape + 'C' + input_tape \n",
    "        self.tape = self.tape[:self.head] + input_tape + self.tape[self.head:]\n",
    "        self.tape_fib = self.tape_fib[:self.head_fib] + '1F1' + self.tape_fib[self.head_fib:]\n",
    "        self.head = N // 2 \n",
    "        self.head_fib = N // 2 - 1\n",
    "\n",
    "     # --------------------------------------------------------------------------------------------\n",
    "\n",
    "        for line in program.splitlines(): \n",
    "            s, a, r, d, s1, a_f, r_f, d_f = line.split(' ') \n",
    "            self.trf[s,a,a_f] = (r, d, s1, r_f, d_f)\n",
    "\n",
    "   \n",
    "    def step(self):\n",
    "        \n",
    "        if (self.state != 'H' and self.state != 'E'):\n",
    "            a = self.tape[self.head]\n",
    "            a_f = self.tape_fib[self.head_fib]\n",
    "            action = self.trf.get((self.state, a, a_f)) \n",
    "            if action: \n",
    "                r, d, s1, r_f, d_f = action \n",
    "                self.tape = self.tape[:self.head] + r + self.tape[self.head+1:]\n",
    "                self.tape_fib = self.tape_fib[:self.head_fib] + r_f + self.tape_fib[self.head_fib+1:]\n",
    "                if d != '*':\n",
    "                    self.head = self.head + (1 if d == 'r' else -1)\n",
    "                if d_f != '*': \n",
    "                    self.head_fib = self.head_fib + (1 if d_f == 'r' else -1)\n",
    "\n",
    "                self.state = s1 \n",
    "\n",
    "    def run(self, max_iter=999999999999):\n",
    "        iter = 0\n",
    "        while (self.state != 'H' and self.state != 'E') and iter < max_iter:\n",
    "            self.step()\n",
    "            iter += 1\n",
    "        if (self.state == 'E'):\n",
    "            result = 0\n",
    "            print(\"The number does NOT belong to the Fibonacci sequence.\")\n",
    "        if (self.state == 'H'):\n",
    "            result = 1\n",
    "            print(\"The number DOES belong to the Fibonacci sequence.\")\n",
    "      \n",
    "        return iter, self.state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwuOEftDu000"
   },
   "source": [
    "### 2.3. Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BpRec__vFp4"
   },
   "source": [
    "To run the program, we need to execute the following code, specifying the input number and the text file (depending on the machine we want to test).\n",
    "\n",
    "Here we give an example for each machine, but one can replace the input number and try any other number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number DOES belong to the Fibonacci sequence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9580, 'H')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 20000 # add more for Fibonacci formula\n",
    "\n",
    "# Binary Turing Machine computing the numbers of the sequence\n",
    "#input_tape = '1100' #example with number 12 in binary (place here any number in binary)\n",
    "#program = open('fibonacci_binary.txt').read()\n",
    "\n",
    "# Unary Turing Machine computing the numbers of the sequence\n",
    "#input_tape = '111111111111111111111' # example with number 21 in unary (place here any number in unary)\n",
    "#program = open('fibonacci_unary_no_formula.txt').read()\n",
    "\n",
    "# Fibonacci formula Turing Machine\n",
    "input_tape = '111' # example with number 3 in unary (place here any number in unary)\n",
    "program = open('fibonacci_formula.txt').read()\n",
    "\n",
    "tm = TuringMachine(program, input_tape, N)\n",
    "tm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvx22Iu45EXx"
   },
   "source": [
    "## 3. Complexity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8KLDv1CLYaU"
   },
   "source": [
    "Once we have run different experiments we can proceed to analyse the complexity of our Turing Machines, by counting the number of steps that our machines need to determine whether an input number belongs the the Fibonacci sequence or not. We are going to study how the number of steps scales with the length N of the input string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPbSf48XY5Je"
   },
   "source": [
    "### 3.1. Binary Fibonacci Turing Machine computing the numbers of the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9EYanH_DxPF"
   },
   "source": [
    "In this section we do a complexity analysis of the \"Binary Fibonacci Turing Machine computing the numbers of the sequence\". We generate 1024 numbers in binary, so we do the study for a total of N=10 bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAOXyFHnEYiw"
   },
   "source": [
    "The following code contains the generation of all the numbers in binary, which we subsequently pass as an input to the Turing Machine. The process explained in section 1.1. is carried out for each input and we recieve as an output the number of steps the machine needed to reach a conclusion (whether the input number belongs to the Fibonacci sequence or not). \n",
    "\n",
    "Using this code, we also discern between the best and worst case executions for each N in terms of steps, and we compute the average number of steps that the machine needed for each N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ehHD3zHrULP5"
   },
   "outputs": [],
   "source": [
    "N = 200 \n",
    "numero_digits = [[]]\n",
    "numero_iteracions = [[]]\n",
    "number_belongs = [[]]\n",
    "worst_best_case = [[]]\n",
    "average_vector = []\n",
    "bits_vector = []\n",
    "worst_vector = []\n",
    "digits = 0\n",
    "digit_actual = 0\n",
    "\n",
    "def generate(n):\n",
    "    q = deque()\n",
    "    q.append('1')\n",
    "\n",
    "    comptador = 0\n",
    "    digit_actual = 1\n",
    "\n",
    "    for i in range(n):\n",
    "        front = str(q.popleft())\n",
    "        q.append(front + '0')\n",
    "        q.append(front + '1')\n",
    "        \n",
    "        digits = len(front) \n",
    "        input_tape = front\n",
    "        \n",
    "        program = open('fibonacci_binary.txt').read()\n",
    "        tm = TuringMachine(program, input_tape, N)\n",
    "        iteracions, belongs = tm.run()\n",
    "\n",
    "        if(digits == digit_actual):\n",
    "            numero_digits[comptador].append(digits)\n",
    "            numero_iteracions[comptador].append(iteracions)\n",
    "            number_belongs[comptador].append(belongs)\n",
    "            worst_best_case[comptador].append(0)\n",
    "        else:\n",
    "            numero_digits.append([digits])\n",
    "            numero_iteracions.append([iteracions])\n",
    "            number_belongs.append([belongs])\n",
    "            worst_best_case.append([0])\n",
    "            comptador+=1\n",
    "\n",
    "        digit_actual = digits\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n = 1023\n",
    "    generate(n)\n",
    "\n",
    "for i in range(len(numero_iteracions)):\n",
    "    num = numero_iteracions[i]\n",
    "    num.sort()\n",
    "    min = num[0]\n",
    "    worst_vector.append(num[len(num)-1])\n",
    "    worst_best_case[i][len(num)-2] = 2\n",
    "    num.pop(0)\n",
    "    num.append(min)\n",
    "    worst_best_case[i][len(num)-1] = 1\n",
    "    average = mean(num)\n",
    "    bits_vector.append(numero_digits[i][0])\n",
    "    average_vector.append(average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1oDIpoLGsP1"
   },
   "source": [
    "Next, we want to find the best polynomial fit to our data points (using the worst case executions for each N). We have found that a 4th degree polynomial gives the best fit, since it gives the smaller mean squared error (the average squared difference between the estimated values and the actual value) without overfitting our data. Nevertheless, we found that the fit is far from being perfect since our data do not follow a perfect behaviour, and this is because of the design of the Turing Machine itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RI_l6mCpIThw",
    "outputId": "e2f5ffab-cc39-4d94-c164-dbc37d636471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best degree:  4\n"
     ]
    }
   ],
   "source": [
    "# Code for finding the degree d of the best polynomial fit.\n",
    "# Once d is computed, we still need to check that it is not overfitting our data\n",
    "\n",
    "x = np.array(bits_vector).reshape(-1, 1)\n",
    "y = np.array(worst_vector)\n",
    "\n",
    "best_degree = -1\n",
    "best_mse = float(\"inf\")\n",
    "\n",
    "for degree in range(1, 5):\n",
    "    polynomial_features = PolynomialFeatures(degree=degree)\n",
    "    x_poly = polynomial_features.fit_transform(x)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_poly, y)\n",
    "    y_poly_pred = model.predict(x_poly)\n",
    "\n",
    "    mse = mean_squared_error(y, y_poly_pred)\n",
    "    if mse < best_mse:\n",
    "        best_degree = degree\n",
    "        best_mse = mse\n",
    "\n",
    "print(\"Best degree: \", best_degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ac1gvQiIJ2o"
   },
   "source": [
    "Finally, we can plot our data points for each N and the 4th degree polynomial fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "5VRoRwrPFEhU",
    "outputId": "2c40e90d-4998-4a00-9dff-cd6a7bbc547e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bits [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "worst steps [4, 197, 672, 1536, 2370, 4119, 5560, 8452, 10792, 15139]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "width": 1
         },
         "marker": {
          "color": "black"
         },
         "mode": "lines",
         "name": "Polynomial fit on worst case (d=4)",
         "type": "scatter",
         "x": [
          1,
          1.183673469387755,
          1.3673469387755102,
          1.5510204081632653,
          1.7346938775510203,
          1.9183673469387754,
          2.1020408163265305,
          2.2857142857142856,
          2.4693877551020407,
          2.6530612244897958,
          2.836734693877551,
          3.0204081632653064,
          3.2040816326530615,
          3.3877551020408165,
          3.5714285714285716,
          3.7551020408163267,
          3.938775510204082,
          4.122448979591837,
          4.3061224489795915,
          4.4897959183673475,
          4.673469387755102,
          4.857142857142858,
          5.040816326530613,
          5.224489795918368,
          5.408163265306123,
          5.591836734693878,
          5.775510204081633,
          5.959183673469388,
          6.142857142857143,
          6.326530612244898,
          6.510204081632653,
          6.6938775510204085,
          6.877551020408164,
          7.061224489795919,
          7.244897959183674,
          7.428571428571429,
          7.612244897959184,
          7.795918367346939,
          7.979591836734694,
          8.16326530612245,
          8.346938775510203,
          8.53061224489796,
          8.714285714285715,
          8.89795918367347,
          9.081632653061225,
          9.26530612244898,
          9.448979591836736,
          9.63265306122449,
          9.816326530612246,
          10
         ],
         "y": [
          22.916083916098046,
          17.54543724612239,
          27.22962191893248,
          51.20628940845535,
          88.76799921391836,
          139.2622188598495,
          202.09132389607777,
          276.7125978977319,
          362.63823246524214,
          459.4353272243386,
          566.7258898260526,
          684.1868359467155,
          811.5499892879598,
          948.6020815767175,
          1095.1847525652229,
          1251.1945500310094,
          1416.5829297769114,
          1591.3562556310653,
          1775.5757994469031,
          1969.3577411031665,
          2172.8731685038874,
          2386.3480775784074,
          2610.0633722813614,
          2844.354864592689,
          3089.613274517631,
          3346.2842300867237,
          3614.8682673558105,
          3895.920830406033,
          4190.052271343829,
          4497.927850300945,
          4820.267735434418,
          5157.847002926598,
          5511.495636985125,
          5882.098529842944,
          6270.5954817583015,
          6677.981201014742,
          7105.30530392111,
          7553.672314811555,
          8024.241666045524,
          8518.227698007764,
          9036.899659108323,
          9581.581705782553,
          10153.652902491107,
          10754.547221719917,
          11385.753543980265,
          12048.815657808667,
          12745.33225976701,
          13476.956954442418,
          14245.39825444736,
          15052.419580419586
         ]
        },
        {
         "marker": {
          "color": [
           "green",
           "red",
           "green",
           "blue",
           "blue",
           "red",
           "green",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "red",
           "green",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "red",
           "green",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "red",
           "green",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "red",
           "green",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "red",
           "green",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "red",
           "green",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "blue",
           "red",
           "green"
          ]
         },
         "mode": "markers",
         "name": "Best case",
         "type": "scatter",
         "x": [
          1,
          2,
          2,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10
         ],
         "y": [
          4,
          197,
          100,
          468,
          672,
          672,
          467,
          1183,
          1183,
          1183,
          1185,
          1186,
          1536,
          1536,
          863,
          1859,
          1859,
          1859,
          1861,
          1862,
          2370,
          2370,
          2370,
          2370,
          2370,
          2370,
          2370,
          2370,
          2370,
          2370,
          1859,
          2792,
          2794,
          3396,
          3396,
          3396,
          3396,
          3396,
          3396,
          3396,
          3396,
          3396,
          3396,
          3396,
          3396,
          3396,
          3398,
          3398,
          3398,
          3398,
          3399,
          3399,
          3400,
          3401,
          4119,
          4119,
          4119,
          4119,
          4119,
          4119,
          4119,
          4119,
          2792,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4725,
          4726,
          4726,
          4726,
          4726,
          4726,
          4726,
          4726,
          4726,
          4729,
          4730,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          5560,
          4725,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6294,
          6299,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7349,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7350,
          7352,
          7352,
          7352,
          7352,
          7352,
          7352,
          7352,
          7352,
          7355,
          7356,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          8452,
          6294,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9423,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9424,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9425,
          9426,
          9426,
          9426,
          9426,
          9426,
          9426,
          9426,
          9426,
          9429,
          9430,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          10792,
          9423,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11925,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11926,
          11930,
          11930,
          11932,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13440,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13441,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13442,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13444,
          13445,
          13445,
          13445,
          13445,
          13445,
          13445,
          13445,
          13445,
          13447,
          13447,
          13448,
          13449,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          15139,
          11925
         ]
        },
        {
         "marker": {
          "color": "purple"
         },
         "mode": "markers",
         "name": "Average case",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10
         ],
         "y": [
          4,
          148.5,
          569.75,
          1231.875,
          2178.6875,
          3520.90625,
          5221.046875,
          7399.0390625,
          10139.98046875,
          13267.380859375
         ]
        },
        {
         "marker": {
          "color": "red"
         },
         "mode": "markers",
         "name": "Worst case",
         "type": "scatter",
         "x": [
          null
         ],
         "y": [
          null
         ]
        },
        {
         "marker": {
          "color": "blue"
         },
         "mode": "markers",
         "name": "Data points",
         "type": "scatter",
         "x": [
          null
         ],
         "y": [
          null
         ]
        }
       ],
       "layout": {
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 50
        },
        "plot_bgcolor": "white",
        "shapes": [
         {
          "line": {
           "color": "black",
           "width": 1
          },
          "type": "rect",
          "x0": 0,
          "x1": 1,
          "xref": "paper",
          "y0": 0,
          "y1": 1,
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "gridcolor": "lightgray",
         "gridwidth": 0.5,
         "linecolor": "black",
         "linewidth": 1,
         "showgrid": true,
         "title": {
          "text": "Bits (N)"
         }
        },
        "yaxis": {
         "gridcolor": "lightgray",
         "gridwidth": 0.5,
         "linecolor": "black",
         "linewidth": 1,
         "showgrid": true,
         "title": {
          "text": "Steps"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"5586e3d1-3fe6-4bb1-b29f-ce6a16e33860\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5586e3d1-3fe6-4bb1-b29f-ce6a16e33860\")) {                    Plotly.newPlot(                        \"5586e3d1-3fe6-4bb1-b29f-ce6a16e33860\",                        [{\"line\":{\"width\":1},\"marker\":{\"color\":\"black\"},\"mode\":\"lines\",\"name\":\"Polynomial fit on worst case (d=4)\",\"x\":[1.0,1.183673469387755,1.3673469387755102,1.5510204081632653,1.7346938775510203,1.9183673469387754,2.1020408163265305,2.2857142857142856,2.4693877551020407,2.6530612244897958,2.836734693877551,3.0204081632653064,3.2040816326530615,3.3877551020408165,3.5714285714285716,3.7551020408163267,3.938775510204082,4.122448979591837,4.3061224489795915,4.4897959183673475,4.673469387755102,4.857142857142858,5.040816326530613,5.224489795918368,5.408163265306123,5.591836734693878,5.775510204081633,5.959183673469388,6.142857142857143,6.326530612244898,6.510204081632653,6.6938775510204085,6.877551020408164,7.061224489795919,7.244897959183674,7.428571428571429,7.612244897959184,7.795918367346939,7.979591836734694,8.16326530612245,8.346938775510203,8.53061224489796,8.714285714285715,8.89795918367347,9.081632653061225,9.26530612244898,9.448979591836736,9.63265306122449,9.816326530612246,10.0],\"y\":[22.916083916098046,17.54543724612239,27.22962191893248,51.20628940845535,88.76799921391836,139.2622188598495,202.09132389607777,276.7125978977319,362.63823246524214,459.4353272243386,566.7258898260526,684.1868359467155,811.5499892879598,948.6020815767175,1095.1847525652229,1251.1945500310094,1416.5829297769114,1591.3562556310653,1775.5757994469031,1969.3577411031665,2172.8731685038874,2386.3480775784074,2610.0633722813614,2844.354864592689,3089.613274517631,3346.2842300867237,3614.8682673558105,3895.920830406033,4190.052271343829,4497.927850300945,4820.267735434418,5157.847002926598,5511.495636985125,5882.098529842944,6270.5954817583015,6677.981201014742,7105.30530392111,7553.672314811555,8024.241666045524,8518.227698007764,9036.899659108323,9581.581705782553,10153.652902491107,10754.547221719917,11385.753543980265,12048.815657808667,12745.33225976701,13476.956954442418,14245.39825444736,15052.419580419586],\"type\":\"scatter\"},{\"marker\":{\"color\":[\"green\",\"red\",\"green\",\"blue\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\",\"green\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"blue\",\"red\",\"green\"]},\"mode\":\"markers\",\"name\":\"Best case\",\"x\":[1,2,2,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10],\"y\":[4,197,100,468,672,672,467,1183,1183,1183,1185,1186,1536,1536,863,1859,1859,1859,1861,1862,2370,2370,2370,2370,2370,2370,2370,2370,2370,2370,1859,2792,2794,3396,3396,3396,3396,3396,3396,3396,3396,3396,3396,3396,3396,3396,3398,3398,3398,3398,3399,3399,3400,3401,4119,4119,4119,4119,4119,4119,4119,4119,2792,4725,4725,4725,4725,4725,4725,4725,4725,4725,4725,4725,4725,4725,4725,4725,4726,4726,4726,4726,4726,4726,4726,4726,4729,4730,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,5560,4725,6294,6294,6294,6294,6294,6294,6294,6294,6294,6294,6294,6294,6294,6294,6294,6299,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7349,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7350,7352,7352,7352,7352,7352,7352,7352,7352,7355,7356,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,8452,6294,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9423,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9424,9425,9425,9425,9425,9425,9425,9425,9425,9425,9425,9425,9425,9425,9425,9425,9425,9426,9426,9426,9426,9426,9426,9426,9426,9429,9430,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,10792,9423,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11925,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11926,11930,11930,11932,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13440,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13441,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13442,13444,13444,13444,13444,13444,13444,13444,13444,13444,13444,13444,13444,13444,13444,13444,13444,13445,13445,13445,13445,13445,13445,13445,13445,13447,13447,13448,13449,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,15139,11925],\"type\":\"scatter\"},{\"marker\":{\"color\":\"purple\"},\"mode\":\"markers\",\"name\":\"Average case\",\"x\":[1,2,3,4,5,6,7,8,9,10],\"y\":[4,148.5,569.75,1231.875,2178.6875,3520.90625,5221.046875,7399.0390625,10139.98046875,13267.380859375],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"markers\",\"name\":\"Worst case\",\"x\":[null],\"y\":[null],\"type\":\"scatter\"},{\"marker\":{\"color\":\"blue\"},\"mode\":\"markers\",\"name\":\"Data points\",\"x\":[null],\"y\":[null],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"showgrid\":true,\"gridcolor\":\"lightgray\",\"gridwidth\":0.5,\"title\":{\"text\":\"Bits (N)\"},\"linecolor\":\"black\",\"linewidth\":1},\"yaxis\":{\"showgrid\":true,\"gridcolor\":\"lightgray\",\"gridwidth\":0.5,\"title\":{\"text\":\"Steps\"},\"linecolor\":\"black\",\"linewidth\":1},\"margin\":{\"l\":50,\"r\":50,\"b\":50,\"t\":50},\"plot_bgcolor\":\"white\",\"shapes\":[{\"line\":{\"color\":\"black\",\"width\":1},\"type\":\"rect\",\"x0\":0,\"x1\":1,\"xref\":\"paper\",\"y0\":0,\"y1\":1,\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('5586e3d1-3fe6-4bb1-b29f-ce6a16e33860');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flat_list = itertools.chain(*numero_digits)\n",
    "flat_list2 = itertools.chain(*numero_iteracions)\n",
    "worst_best = itertools.chain(*worst_best_case)\n",
    "\n",
    "w_b_case = np.array(list(worst_best))\n",
    "color = w_b_case.astype(str)\n",
    "color[w_b_case==0] = \"blue\"\n",
    "color[w_b_case==1] = \"green\"\n",
    "color[w_b_case==2] = \"red\"\n",
    "\n",
    "\n",
    "print(\"bits\", bits_vector)\n",
    "print(\"worst steps\", worst_vector)\n",
    "\n",
    "coef = np.polyfit(bits_vector,worst_vector,4)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "\n",
    "y1=[]\n",
    "x1 = np.linspace((np.array(x)).min(),(np.array(x)).max(),num=50)\n",
    "for value in x1:\n",
    "    p = poly1d_fn(value)\n",
    "    y1.append(p)\n",
    "\n",
    "Fig = go.Figure(\n",
    "    data=[go.Scatter(x=list(x1), y= y1, mode='lines',line=dict(width=1), name = 'Polynomial fit on worst case (d=4)', marker_color = \"black\"),\n",
    "          go.Scatter(x=list(flat_list), y= list(flat_list2), mode='markers',marker_color = color, name = 'Best case'),\n",
    "          go.Scatter(x=bits_vector, y=average_vector, mode=\"markers\", marker_color=\"purple\",name='Average case')]\n",
    ")\n",
    "Fig.add_trace(\n",
    "    go.Scatter(x=[None], y=[None], mode='markers', marker_color=\"red\", name='Worst case')\n",
    ")\n",
    "Fig.add_trace(\n",
    "    go.Scatter(x=[None], y=[None], mode='markers', marker_color=\"blue\", name='Data points')\n",
    ")\n",
    "Fig.update_layout(xaxis=dict(showgrid=True, gridcolor='lightgray', gridwidth=0.5), \n",
    "                  yaxis=dict(showgrid=True, gridcolor='lightgray', gridwidth=0.5))\n",
    "Fig.update_layout(\n",
    "    xaxis_title=\"Bits (N)\",\n",
    "    yaxis_title=\"Steps\",\n",
    "    xaxis=dict(linecolor='black', linewidth=1),\n",
    "    yaxis=dict(linecolor='black', linewidth=1),\n",
    "    margin=dict(l=50, r=50, b=50, t=50),\n",
    "    plot_bgcolor='white',\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type='rect',\n",
    "            xref='paper', yref='paper',\n",
    "            x0=0, y0=0,\n",
    "            x1=1, y1=1,\n",
    "            line=dict(color='black', width=1)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "Fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CA_BQwpIWm1"
   },
   "source": [
    "In this plot we display the number of steps needed to decide if the input number belongs to the Fibonacci sequence. Since we can build $2^N$ binary numbers for each N, we have several points for each N representing these numbers. The green dots indicate the best case execution for each N, the red points the worst case, and the purple points the average case. The blue points are simply other executions. \n",
    "\n",
    "\n",
    "\n",
    "We can see that the behviour of the worst case data points can be approximately fitted with the 4th degree polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3sX2QsCczBk"
   },
   "source": [
    "### 3.2. Unary Fibonacci Turing Machine computing the numbers of the sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_sXnt-bdWcq"
   },
   "source": [
    "We can do a similar complexity study for the Turing Machine that computes the numbers of the Fibonacci sequence in unary. To have a better eyesight of the behaviour of the machine, we generate 55 numbers in unary and each of them are passed as an the input tape to the Turing Machine. We proceed the same way as in 3.1; we find the degree of the best polynomial fit and we see how it adjusts to out data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "Ctm_H9rtT7w2",
    "outputId": "071abe4a-11c9-4d45-a5ac-7cb72ae6f1a8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "width": 1
         },
         "marker": {
          "color": "black"
         },
         "mode": "lines",
         "name": "Polynomial fit (d=3)",
         "type": "scatter",
         "x": [
          0,
          0.7142857142857143,
          1.4285714285714286,
          2.142857142857143,
          2.857142857142857,
          3.5714285714285716,
          4.285714285714286,
          5,
          5.714285714285714,
          6.428571428571429,
          7.142857142857143,
          7.857142857142858,
          8.571428571428571,
          9.285714285714286,
          10,
          10.714285714285715,
          11.428571428571429,
          12.142857142857142,
          12.857142857142858,
          13.571428571428571,
          14.285714285714286,
          15,
          15.714285714285715,
          16.42857142857143,
          17.142857142857142,
          17.857142857142858,
          18.571428571428573,
          19.285714285714285,
          20,
          20.714285714285715,
          21.42857142857143,
          22.142857142857142,
          22.857142857142858,
          23.571428571428573,
          24.285714285714285,
          25,
          25.714285714285715,
          26.42857142857143,
          27.142857142857142,
          27.857142857142858,
          28.571428571428573,
          29.285714285714285,
          30,
          30.714285714285715,
          31.42857142857143,
          32.142857142857146,
          32.85714285714286,
          33.57142857142857,
          34.285714285714285,
          35
         ],
         "y": [
          -5.5936739680023315,
          4.474650665567317,
          19.857525468733574,
          40.55903193657501,
          66.5832515641702,
          97.93426584659774,
          134.6161562789362,
          176.63300435626414,
          223.98889157366014,
          276.68789942620276,
          334.73410940897065,
          398.1316030170423,
          466.8844617454963,
          540.9967670894114,
          620.4726005438658,
          705.3160436039386,
          795.531177764708,
          891.1220845212522,
          992.0928453686508,
          1098.4475418019815,
          1210.1902553163236,
          1327.325067406755,
          1449.8560595683546,
          1577.787313296201,
          1711.122910085372,
          1849.8669314309475,
          1994.0234588280057,
          2143.596573771624,
          2298.590357756883,
          2459.0088922788595,
          2624.8562588326336,
          2796.1365389132816,
          2972.853814015885,
          3155.0121656355204,
          3342.615675267266,
          3535.668424406202,
          3734.1744945474065,
          3938.137967185957,
          4147.562923816934,
          4362.4534459354145,
          4582.813615036478,
          4808.6475126152,
          5039.959220166665,
          5276.752819185947,
          5519.032391168126,
          5766.80201760828,
          6020.065780001489,
          6278.827759842827,
          6543.092038627379,
          6812.862697850222
         ]
        },
        {
         "marker": {
          "color": "green"
         },
         "mode": "markers",
         "name": "Data points",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55
         ],
         "y": [
          1,
          2,
          17,
          54,
          109,
          110,
          242,
          243,
          244,
          508,
          509,
          510,
          511,
          512,
          1181,
          1182,
          1183,
          1184,
          1185,
          1186,
          1187,
          1188,
          2753,
          2754,
          2755,
          2756,
          2757,
          2758,
          2759,
          2760,
          2761,
          2762,
          2763,
          2764,
          2765,
          6814,
          6815,
          6816,
          6817,
          6818,
          6819,
          6820,
          6821,
          6822,
          6823,
          6824,
          6825,
          6826,
          6827,
          6828,
          6829,
          6830,
          6831,
          6832,
          6833,
          6834
         ]
        },
        {
         "marker": {
          "color": "red"
         },
         "mode": "markers",
         "name": "Data points used for the fit",
         "type": "scatter",
         "x": [
          0,
          4,
          6,
          9,
          14,
          22,
          35
         ],
         "y": [
          1,
          109,
          242,
          508,
          1181,
          2753,
          6814
         ]
        }
       ],
       "layout": {
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 50
        },
        "plot_bgcolor": "white",
        "shapes": [
         {
          "line": {
           "color": "black",
           "width": 1
          },
          "type": "rect",
          "x0": 0,
          "x1": 1,
          "xref": "paper",
          "y0": 0,
          "y1": 1,
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "gridcolor": "lightgray",
         "gridwidth": 0.5,
         "linecolor": "black",
         "linewidth": 1,
         "showgrid": true,
         "title": {
          "text": "Bits (N)"
         }
        },
        "yaxis": {
         "gridcolor": "lightgray",
         "gridwidth": 0.5,
         "linecolor": "black",
         "linewidth": 1,
         "showgrid": true,
         "title": {
          "text": "Steps"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"8fb74177-07e1-47c0-85be-66a46e04e796\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8fb74177-07e1-47c0-85be-66a46e04e796\")) {                    Plotly.newPlot(                        \"8fb74177-07e1-47c0-85be-66a46e04e796\",                        [{\"line\":{\"width\":1},\"marker\":{\"color\":\"black\"},\"mode\":\"lines\",\"name\":\"Polynomial fit (d=3)\",\"x\":[0.0,0.7142857142857143,1.4285714285714286,2.142857142857143,2.857142857142857,3.5714285714285716,4.285714285714286,5.0,5.714285714285714,6.428571428571429,7.142857142857143,7.857142857142858,8.571428571428571,9.285714285714286,10.0,10.714285714285715,11.428571428571429,12.142857142857142,12.857142857142858,13.571428571428571,14.285714285714286,15.0,15.714285714285715,16.42857142857143,17.142857142857142,17.857142857142858,18.571428571428573,19.285714285714285,20.0,20.714285714285715,21.42857142857143,22.142857142857142,22.857142857142858,23.571428571428573,24.285714285714285,25.0,25.714285714285715,26.42857142857143,27.142857142857142,27.857142857142858,28.571428571428573,29.285714285714285,30.0,30.714285714285715,31.42857142857143,32.142857142857146,32.85714285714286,33.57142857142857,34.285714285714285,35.0],\"y\":[-5.5936739680023315,4.474650665567317,19.857525468733574,40.55903193657501,66.5832515641702,97.93426584659774,134.6161562789362,176.63300435626414,223.98889157366014,276.68789942620276,334.73410940897065,398.1316030170423,466.8844617454963,540.9967670894114,620.4726005438658,705.3160436039386,795.531177764708,891.1220845212522,992.0928453686508,1098.4475418019815,1210.1902553163236,1327.325067406755,1449.8560595683546,1577.787313296201,1711.122910085372,1849.8669314309475,1994.0234588280057,2143.596573771624,2298.590357756883,2459.0088922788595,2624.8562588326336,2796.1365389132816,2972.853814015885,3155.0121656355204,3342.615675267266,3535.668424406202,3734.1744945474065,3938.137967185957,4147.562923816934,4362.4534459354145,4582.813615036478,4808.6475126152,5039.959220166665,5276.752819185947,5519.032391168126,5766.80201760828,6020.065780001489,6278.827759842827,6543.092038627379,6812.862697850222],\"type\":\"scatter\"},{\"marker\":{\"color\":\"green\"},\"mode\":\"markers\",\"name\":\"Data points\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55],\"y\":[1,2,17,54,109,110,242,243,244,508,509,510,511,512,1181,1182,1183,1184,1185,1186,1187,1188,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,6814,6815,6816,6817,6818,6819,6820,6821,6822,6823,6824,6825,6826,6827,6828,6829,6830,6831,6832,6833,6834],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"markers\",\"name\":\"Data points used for the fit\",\"x\":[0,4,6,9,14,22,35],\"y\":[1,109,242,508,1181,2753,6814],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"Bits (N)\"},\"linecolor\":\"black\",\"linewidth\":1,\"showgrid\":true,\"gridcolor\":\"lightgray\",\"gridwidth\":0.5},\"yaxis\":{\"title\":{\"text\":\"Steps\"},\"linecolor\":\"black\",\"linewidth\":1,\"showgrid\":true,\"gridcolor\":\"lightgray\",\"gridwidth\":0.5},\"margin\":{\"l\":50,\"r\":50,\"b\":50,\"t\":50},\"plot_bgcolor\":\"white\",\"shapes\":[{\"line\":{\"color\":\"black\",\"width\":1},\"type\":\"rect\",\"x0\":0,\"x1\":1,\"xref\":\"paper\",\"y0\":0,\"y1\":1,\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8fb74177-07e1-47c0-85be-66a46e04e796');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 500 # tape length, initialize to a large value if you need it\n",
    "numero_digits = []\n",
    "numero_iteracions = []\n",
    "number_belongs = []\n",
    "fit_digits=[]\n",
    "fit_steps=[]\n",
    "comptador = 0\n",
    "\n",
    "for digits in range (56):\n",
    "    numero_digits.append(digits)\n",
    "    input_tape = ''.join(['1']*digits)\n",
    "\n",
    "    # UNARI\n",
    "    program = open('fibonacci_unary_no_formula.txt').read()\n",
    "\n",
    "    tm = TuringMachine(program, input_tape, N)\n",
    "    iteracions, belongs = tm.run()\n",
    "    numero_iteracions.append(iteracions)\n",
    "    number_belongs.append(belongs)\n",
    "\n",
    "    if (belongs == 'E' and comptador == 0):\n",
    "        fit_steps.append(iteracions)\n",
    "        fit_digits.append(digits)\n",
    "        comptador = 1\n",
    "    if (belongs == 'H'):\n",
    "        comptador = 0\n",
    "\n",
    "coef = np.polyfit(fit_digits,fit_steps,3)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "\n",
    "fit_y=[]\n",
    "fit_x = np.linspace((np.array(fit_digits)).min(),(np.array(fit_digits)).max(),num=50)\n",
    "for value in fit_x:\n",
    "    p = poly1d_fn(value)\n",
    "    fit_y.append(p)\n",
    "\n",
    "Fig = go.Figure(\n",
    "    data=[go.Scatter(x=list(fit_x), y= fit_y, mode='lines',line=dict(width=1), name = 'Polynomial fit (d=3)', marker_color = \"black\"),\n",
    "          go.Scatter(x=numero_digits, y= numero_iteracions, mode='markers',marker_color = \"green\", name = 'Data points'),\n",
    "          go.Scatter(x=fit_digits, y= fit_steps, mode='markers', name = 'Data points used for the fit', marker_color = \"red\"),]\n",
    ")\n",
    "Fig.update_layout(\n",
    "    xaxis_title=\"Bits (N)\",\n",
    "    yaxis_title=\"Steps\",\n",
    "    xaxis=dict(linecolor='black', linewidth=1),\n",
    "    yaxis=dict(linecolor='black', linewidth=1),\n",
    "    margin=dict(l=50, r=50, b=50, t=50),\n",
    "    plot_bgcolor='white',\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type='rect',\n",
    "            xref='paper', yref='paper',\n",
    "            x0=0, y0=0,\n",
    "            x1=1, y1=1,\n",
    "            line=dict(color='black', width=1)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "Fig.update_layout(xaxis=dict(showgrid=True, gridcolor='lightgray', gridwidth=0.5), \n",
    "                  yaxis=dict(showgrid=True, gridcolor='lightgray', gridwidth=0.5))\n",
    "Fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T25K_qk4eNll"
   },
   "source": [
    "We can see a special behaviour in our data points: for certain consecutive numbers, the number of steps that the Turin Machine needs to determine whether the number N belongs to the FS is almost the same (diverging only by one step). This behaviour can be explained as follows: the difference of steps needed to halt the machine for a number $n$ belonging to the FS, is notably smaller than the number of steps needed for the immediate following number $n+1$ (which in general does not belong to FS), since the addition subroutine must be run at least once more for $n+1$. On the other hand, for the immediate following number of a non-belonging N, there is only one step difference, since the addition subroutine is used the same amount of times; we simply need one more step to compare the input number and the Fibonacci number of the additional tape. \n",
    "\n",
    "Therefore, the marker corresponding to the biggest N of a constant region in the plot, indicates a number belonging to the Fibonacci sequence. All the other points in a constant region, correspond to numbers that do not belong to FS. We have made the regression using the red dots, which are the immidiate (non-belonging) numbers to a belonging number. \n",
    "\n",
    "We obtain that a 3rd degree polynomial is a pretty good fit to our data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0MIA3fPDOuS"
   },
   "source": [
    "### 3.3. Fibonacci formula Turing Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we perform a complexity study for the last Turing Machine which consists in calculating the Fibonacci formula. For this analysis we have used 12 bits which correspond to the first twelve integers. \n",
    "\n",
    "After colleting the number of iterations for each $N$, we have also fitted our data to analyse the complexity of this Machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3000000 # tape length, initialize to a large value if you need it\n",
    "program = open('TM_formula.txt').read()\n",
    "input_tape = ''\n",
    "rows = []\n",
    "for num in range(0, 12):\n",
    "    input_tape = input_tape + '1'\n",
    "    tm = TuringMachine(program, input_tape, N)\n",
    "    max_iter, final_state = tm.run()\n",
    "    if final_state == 'H':\n",
    "        rows.append([len(input_tape), bin(len(input_tape)), \"yes\", max_iter])\n",
    "    else: \n",
    "        rows.append([len(input_tape), bin(len(input_tape)), \"no\", max_iter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Input decimal Input Binary Fibonacci  Iterations\n",
      "0               1          0b1       yes         426\n",
      "1               2         0b10       yes        3330\n",
      "2               3         0b11       yes        9580\n",
      "3               4        0b100        no       59754\n",
      "4               5        0b101       yes      139619\n",
      "5               6        0b110        no      331890\n",
      "6               7        0b111        no      617506\n",
      "7               8       0b1000       yes      593387\n",
      "8               9       0b1001        no     2176969\n",
      "9              10       0b1010        no     3359911\n",
      "10             11       0b1011        no     5008603\n",
      "11             12       0b1100        no     7247461\n"
     ]
    }
   ],
   "source": [
    "headers=[\"Input decimal\", \"Input Binary\", \"Fibonacci\", \"Iterations\"]\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous cases, we can proceed to perform the polynomial fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "width": 1
         },
         "marker": {
          "color": "black"
         },
         "mode": "lines",
         "name": "Polynomial fit (d=4)",
         "type": "scatter",
         "x": [
          1,
          1.2244897959183674,
          1.4489795918367347,
          1.6734693877551021,
          1.8979591836734695,
          2.1224489795918364,
          2.3469387755102042,
          2.571428571428571,
          2.795918367346939,
          3.020408163265306,
          3.2448979591836733,
          3.4693877551020407,
          3.693877551020408,
          3.9183673469387754,
          4.142857142857142,
          4.36734693877551,
          4.591836734693878,
          4.816326530612245,
          5.040816326530612,
          5.26530612244898,
          5.489795918367347,
          5.714285714285714,
          5.938775510204081,
          6.163265306122449,
          6.387755102040816,
          6.612244897959184,
          6.836734693877551,
          7.061224489795919,
          7.285714285714286,
          7.510204081632653,
          7.73469387755102,
          7.959183673469388,
          8.183673469387756,
          8.408163265306122,
          8.63265306122449,
          8.857142857142858,
          9.081632653061224,
          9.306122448979592,
          9.53061224489796,
          9.755102040816327,
          9.979591836734693,
          10.204081632653061,
          10.428571428571429,
          10.653061224489797,
          10.877551020408163,
          11.10204081632653,
          11.326530612244898,
          11.551020408163266,
          11.775510204081632,
          12
         ],
         "y": [
          -48384.66025641549,
          -9837.009857436293,
          20496.447700894496,
          43461.62273143284,
          59902.13144419168,
          70659.2959463406,
          76572.1442422056,
          78477.41023326962,
          77209.53371817205,
          73600.66039270913,
          68480.64184983377,
          62677.03557965526,
          57015.104969439446,
          52317.81930360955,
          49405.85376374534,
          49097.58942858229,
          52209.11327401316,
          59554.21817308839,
          71944.40289601253,
          90188.87211014947,
          115094.53638001822,
          147466.01216729463,
          188105.6218308122,
          237813.39362656,
          297387.0617076837,
          367622.0661244866,
          449311.5528244275,
          543246.3736521227,
          650215.0863493449,
          771003.9545550246,
          906396.9478052466,
          1057175.7415332536,
          1224119.7170694454,
          1408005.961641376,
          1609609.2683737618,
          1829702.13628847,
          2069054.770304525,
          2328435.0812381124,
          2608608.6858025724,
          2910338.906608396,
          3234386.7721632393,
          3581511.0168719133,
          3952468.0810363824,
          4348012.110855769,
          4768894.958426348,
          5215866.18174156,
          5689673.044692,
          6191060.517065414,
          6720771.274546705,
          7279545.698717945
         ]
        },
        {
         "marker": {
          "color": "red"
         },
         "mode": "markers",
         "name": "Data points used for the fit",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12
         ],
         "y": [
          426,
          3330,
          9580,
          59754,
          139619,
          331890,
          617506,
          593387,
          2176969,
          3359911,
          5008603,
          7247461
         ]
        }
       ],
       "layout": {
        "margin": {
         "b": 50,
         "l": 50,
         "r": 50,
         "t": 50
        },
        "plot_bgcolor": "white",
        "shapes": [
         {
          "line": {
           "color": "black",
           "width": 1
          },
          "type": "rect",
          "x0": 0,
          "x1": 1,
          "xref": "paper",
          "y0": 0,
          "y1": 1,
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "gridcolor": "lightgray",
         "gridwidth": 0.5,
         "linecolor": "black",
         "linewidth": 1,
         "showgrid": true,
         "title": {
          "text": "Bits (N)"
         }
        },
        "yaxis": {
         "gridcolor": "lightgray",
         "gridwidth": 0.5,
         "linecolor": "black",
         "linewidth": 1,
         "showgrid": true,
         "title": {
          "text": "Steps"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"ce183474-0500-4f75-9e74-6d395aef8ecd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ce183474-0500-4f75-9e74-6d395aef8ecd\")) {                    Plotly.newPlot(                        \"ce183474-0500-4f75-9e74-6d395aef8ecd\",                        [{\"line\":{\"width\":1},\"marker\":{\"color\":\"black\"},\"mode\":\"lines\",\"name\":\"Polynomial fit (d=4)\",\"x\":[1.0,1.2244897959183674,1.4489795918367347,1.6734693877551021,1.8979591836734695,2.1224489795918364,2.3469387755102042,2.571428571428571,2.795918367346939,3.020408163265306,3.2448979591836733,3.4693877551020407,3.693877551020408,3.9183673469387754,4.142857142857142,4.36734693877551,4.591836734693878,4.816326530612245,5.040816326530612,5.26530612244898,5.489795918367347,5.714285714285714,5.938775510204081,6.163265306122449,6.387755102040816,6.612244897959184,6.836734693877551,7.061224489795919,7.285714285714286,7.510204081632653,7.73469387755102,7.959183673469388,8.183673469387756,8.408163265306122,8.63265306122449,8.857142857142858,9.081632653061224,9.306122448979592,9.53061224489796,9.755102040816327,9.979591836734693,10.204081632653061,10.428571428571429,10.653061224489797,10.877551020408163,11.10204081632653,11.326530612244898,11.551020408163266,11.775510204081632,12.0],\"y\":[-48384.66025641549,-9837.009857436293,20496.447700894496,43461.62273143284,59902.13144419168,70659.2959463406,76572.1442422056,78477.41023326962,77209.53371817205,73600.66039270913,68480.64184983377,62677.03557965526,57015.104969439446,52317.81930360955,49405.85376374534,49097.58942858229,52209.11327401316,59554.21817308839,71944.40289601253,90188.87211014947,115094.53638001822,147466.01216729463,188105.6218308122,237813.39362656,297387.0617076837,367622.0661244866,449311.5528244275,543246.3736521227,650215.0863493449,771003.9545550246,906396.9478052466,1057175.7415332536,1224119.7170694454,1408005.961641376,1609609.2683737618,1829702.13628847,2069054.770304525,2328435.0812381124,2608608.6858025724,2910338.906608396,3234386.7721632393,3581511.0168719133,3952468.0810363824,4348012.110855769,4768894.958426348,5215866.18174156,5689673.044692,6191060.517065414,6720771.274546705,7279545.698717945],\"type\":\"scatter\"},{\"marker\":{\"color\":\"red\"},\"mode\":\"markers\",\"name\":\"Data points used for the fit\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12],\"y\":[426,3330,9580,59754,139619,331890,617506,593387,2176969,3359911,5008603,7247461],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"Bits (N)\"},\"linecolor\":\"black\",\"linewidth\":1,\"showgrid\":true,\"gridcolor\":\"lightgray\",\"gridwidth\":0.5},\"yaxis\":{\"title\":{\"text\":\"Steps\"},\"linecolor\":\"black\",\"linewidth\":1,\"showgrid\":true,\"gridcolor\":\"lightgray\",\"gridwidth\":0.5},\"margin\":{\"l\":50,\"r\":50,\"b\":50,\"t\":50},\"plot_bgcolor\":\"white\",\"shapes\":[{\"line\":{\"color\":\"black\",\"width\":1},\"type\":\"rect\",\"x0\":0,\"x1\":1,\"xref\":\"paper\",\"y0\":0,\"y1\":1,\"yref\":\"paper\"}]},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('ce183474-0500-4f75-9e74-6d395aef8ecd');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit_digits = df.get(\"Input decimal\")\n",
    "fit_steps = df.get(\"Iterations\")\n",
    "\n",
    "coef = np.polyfit(fit_digits,fit_steps,4)\n",
    "poly1d_fn = np.poly1d(coef) \n",
    "\n",
    "fit_y=[]\n",
    "fit_x = np.linspace((np.array(fit_digits)).min(),(np.array(fit_digits)).max(),num=50)\n",
    "for value in fit_x:\n",
    "    p = poly1d_fn(value)\n",
    "    fit_y.append(p)\n",
    "\n",
    "Fig = go.Figure(\n",
    "    data=[go.Scatter(x=list(fit_x), y= fit_y, mode='lines',line=dict(width=1), name = 'Polynomial fit (d=4)', marker_color = \"black\"),\n",
    "          go.Scatter(x=fit_digits, y= fit_steps, mode='markers', name = 'Data points used for the fit', marker_color = \"red\"),]\n",
    ")\n",
    "Fig.update_layout(\n",
    "    xaxis_title=\"Bits (N)\",\n",
    "    yaxis_title=\"Steps\",\n",
    "    xaxis=dict(linecolor='black', linewidth=1),\n",
    "    yaxis=dict(linecolor='black', linewidth=1),\n",
    "    margin=dict(l=50, r=50, b=50, t=50),\n",
    "    plot_bgcolor='white',\n",
    "    shapes=[\n",
    "        dict(\n",
    "            type='rect',\n",
    "            xref='paper', yref='paper',\n",
    "            x0=0, y0=0,\n",
    "            x1=1, y1=1,\n",
    "            line=dict(color='black', width=1)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "Fig.update_layout(xaxis=dict(showgrid=True, gridcolor='lightgray', gridwidth=0.5), \n",
    "                  yaxis=dict(showgrid=True, gridcolor='lightgray', gridwidth=0.5))\n",
    "Fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this figure we present the iterations that were needed for this Turing Machine to guess if a number is in the Fibonacci sequence. The numbers used are limited to $N\\in[1,12]$ because the computational cost was extremely high for greater values of $N$. \n",
    "In the plot is also shown the polynomial fit of the data which results in a polynomial of degree 4.\n",
    "\n",
    "Recall that the Turing Machine for this case computes the equation $5N^2 + 4$ and checks if this result is a perfect square. \n",
    "\n",
    "- Therefore, the best case scenario for the \"Fibonnaci formula Turing Machine\" will be that number that is in the sequence and provides a perfect square when calculating $5N^2 + 4$. Notice that this is the case for number $8$ as $5\\cdot8^2 + 4 = 324$, which is a perfect square. Thus, we can see how the number of iterations needed to calculate the formula is less than what is expected.The same happens with number $3$.\n",
    "\n",
    "\n",
    "- However, for $N = 5$ (a number that also belongs to the sequence), the perfect square is achieved when computing $5N^2 - 4$. Thus, we expect to need more iterations to guess if the number belongs to the sequence since the TM will first check if $5N^2 + 4$ is a perfect square and then compute the other possibility. \n",
    "\n",
    "\n",
    "- Finally, the worst case scenario will be the one in which the number $N$ does not belong to the sequence because the Turing Machine will have to check both formulas and then reject the number.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "635fX9ckKv2e"
   },
   "source": [
    "## 4. Comparison and conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlQZwDr28TY2"
   },
   "source": [
    "We can draw some conclusions from the results obtained after doing the complexity analysis. \n",
    "\n",
    "1. We have found that a 3rd degree polynomial fits our data for the Unary Turing Machine, while a 4th degree polynomial is needed for the Binary Turing Machine. \n",
    "\n",
    "\n",
    "2. In the plots we can appreciate that, when increasing the input length N, the number of steps needed to halt the machine scales more rapidly in the case of the binary TM in comparison with the unary TM. Nevertheless, for a specific number k, the binary TM gives a better performance in comparision to the unary TM. That is, the binary TM needs less steps than the unary TM to determine if a number k (expressed in binary and unary respectively) belongs to the Fibonacci sequence.\n",
    "\n",
    "\n",
    "3. For the Formula Turing Machine, the number of iterations increases with $N^4$. \n",
    "\n",
    "\n",
    "4. Taking into account the number of steps needed for specific length $N$ (number of bits), we can conclude that the formula Turing Machine presents the worst performance ever. Thus, to determine if a number belongs to the Fibonacci sequence we should use the first two Turing Machines exposed.\n",
    "\n",
    "In this work we have designed and compared three different Fibonacci Turing Machines from scratch and we have analyzed the computational complexity by counting the number of iterations. We have managed to create two Machines that have a good performance since we can find a solution to our problem in a polynomial time. However, we have also build an \"impossible\" Turing Machine, but as Alan Turing once said, \n",
    "\n",
    "<br>\n",
    "<center> “Those who can imagine anything, can create the impossible.”\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
